{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karan/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-11-14 15:05:12.328614: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-14 15:05:12.706241: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-14 15:05:13.470825: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/activations_tf.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtf_keras\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py:1764\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1763\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1764\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   1765\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:38\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[0;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mactivations_tf\u001b[39;00m \u001b[39mimport\u001b[39;00m get_tf_activation\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfiguration_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m PretrainedConfig\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/activations_tf.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[39mif\u001b[39;00m parse(keras\u001b[39m.\u001b[39m__version__)\u001b[39m.\u001b[39mmajor \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`pip install tf-keras`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_gelu\u001b[39m(x):\n",
      "\u001b[0;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py:1764\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1763\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1764\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   1765\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/integrations/integration_utils.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpackaging\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__ \u001b[39mas\u001b[39;00m version\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py:1754\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1753\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m-> 1754\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[1;32m   1755\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1766\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1767\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1768\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1769\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m \u001b[39mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m KMeans\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m export_dynamic_quantized_onnx_model, export_optimized_onnx_model\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcross_encoder\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mCrossEncoder\u001b[39;00m \u001b[39mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mLoggingHandler\u001b[39;00m \u001b[39mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m annotations\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mCrossEncoder\u001b[39;00m \u001b[39mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m      5\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mCrossEncoder\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mSentenceEvaluator\u001b[39;00m \u001b[39mimport\u001b[39;00m SentenceEvaluator\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreaders\u001b[39;00m \u001b[39mimport\u001b[39;00m InputExample\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mSentenceTransformer\u001b[39;00m \u001b[39mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m fullname, get_device_name, import_from_string\n\u001b[1;32m     23\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m is_torch_npu_available\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdynamic_module_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_class_from_dynamic_module, get_relative_import_files\n\u001b[0;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_card\u001b[39;00m \u001b[39mimport\u001b[39;00m SentenceTransformerModelCardData, generate_model_card\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msentence_transformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msimilarity_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m SimilarityFunction\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __MODEL_HUB_ORGANIZATION__, __version__\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/model_card.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautonotebook\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m TrainerCallback\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mintegrations\u001b[39;00m \u001b[39mimport\u001b[39;00m CodeCarbonCallback\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodelcard\u001b[39;00m \u001b[39mimport\u001b[39;00m make_markdown_table\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer_callback\u001b[39;00m \u001b[39mimport\u001b[39;00m TrainerControl, TrainerState\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py:1754\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1752\u001b[0m     value \u001b[39m=\u001b[39m Placeholder\n\u001b[1;32m   1753\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m-> 1754\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[1;32m   1755\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1756\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1764\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1765\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1766\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1767\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1768\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1769\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from fuzzywuzzy import fuzz\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15374\n",
      "7329\n"
     ]
    }
   ],
   "source": [
    "with open('./Dataset/fact_checks.json', 'r') as f:\n",
    "    fact_check_db = json.load(f)\n",
    "\n",
    "num_facts_to_load = int(len(fact_check_db) * 0.1)\n",
    "facts_subset = fact_check_db[:num_facts_to_load]\n",
    "print(len(facts_subset))\n",
    "\n",
    "with open('./Dataset/posts.json', 'r') as f:\n",
    "    posts = json.load(f)\n",
    "num_posts_to_load = int(len(posts) * 0.3)\n",
    "posts_subset = posts[:num_posts_to_load]\n",
    "print(len(posts_subset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model** Implementation-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_model(multi=True):\n",
    "#     if multi:\n",
    "#         model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "#     else:\n",
    "#         model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#     return model\n",
    "\n",
    "# def semantic_clustering(corpus, model, k=10):\n",
    "#     corpus_embeddings = model.encode(corpus)\n",
    "    \n",
    "#     kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "#     clusters = kmeans.fit_predict(corpus_embeddings)\n",
    "\n",
    "#     cluster_groups = {i: [] for i in range(k)}\n",
    "#     for idx, cluster_id in enumerate(clusters):\n",
    "#         cluster_groups[cluster_id].append(corpus[idx])\n",
    "    \n",
    "#     labels = assign_labels(cluster_groups)\n",
    "    \n",
    "#     return clusters, labels\n",
    "\n",
    "# def assign_labels(cluster_groups):\n",
    "#     generator = pipeline('text-generation', model='gpt2')\n",
    "#     labels = []\n",
    "#     for cluster_id, items in cluster_groups.items():\n",
    "#         prompt = f\"Assign a semantic label to the following claims:\\n\"\n",
    "#         for item in items[:5]:  # Limit to first 5 items to avoid exceeding max length\n",
    "#             prompt += f\"- {item}\\n\"\n",
    "#         prompt += \"Label:\"\n",
    "        \n",
    "#         response = generator(prompt, max_length=len(prompt) + 10, num_return_sequences=1)\n",
    "#         label = response[0]['generated_text'].split(\"Label:\")[-1].strip()\n",
    "#         labels.append(label)\n",
    "#     return labels\n",
    "\n",
    "# def fuzzymatch(query, labels, cluster_groups):\n",
    "#     matched_clusters = []\n",
    "#     for idx, label in enumerate(labels):\n",
    "#         score = fuzz.ratio(query, label)\n",
    "#         if score > 60:  # Adjust threshold\n",
    "#             matched_clusters.append(cluster_groups[idx])\n",
    "#     return matched_clusters\n",
    "\n",
    "# def evaluate_supportiveness(query, cluster):\n",
    "#     classifier = pipeline('text-classification', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "    \n",
    "#     supportive_claims = []\n",
    "#     for claim in cluster:\n",
    "#         text = f\"Query: {query}\\nClaim: {claim}\"\n",
    "#         result = classifier(text)[0]\n",
    "#         if result['label'] == 'POSITIVE' and result['score'] > 0.6:  # Adjust threshold as needed\n",
    "#             supportive_claims.append(claim)\n",
    "    \n",
    "#     return supportive_claims\n",
    "\n",
    "# # Main function\n",
    "# def fasttrack_algorithm(queries, corpus, multi=True):\n",
    "#     model = load_model(multi)\n",
    "#     Dsel = []\n",
    "    \n",
    "#     # Stage 1: Semantic Clustering\n",
    "#     clusters, labels = semantic_clustering(corpus, model, k=10)\n",
    "    \n",
    "#     # Stage 2: Tracing (for each query)\n",
    "#     for query in queries:\n",
    "#         Dq = [] \n",
    "        \n",
    "#         matched_clusters = fuzzymatch(query, labels, clusters)\n",
    "        \n",
    "#         for cluster in matched_clusters:\n",
    "#             supportive_claims = evaluate_supportiveness(query, cluster)\n",
    "#             Dq.extend(supportive_claims)\n",
    "        \n",
    "#         Dsel.extend(Dq)\n",
    "    \n",
    "#     return Dsel\n",
    "\n",
    "\n",
    "# queries = [\n",
    "#     f\"{post['translated_ocr']}\"\n",
    "#     for post in posts_subset\n",
    "# ]\n",
    "\n",
    "# corpus = [\n",
    "#     f\"{fact['translation_sentence']}\"\n",
    "#     for fact in facts_subset\n",
    "# ]\n",
    "# fasttrack_algorithm(queries,corpus,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model** Implementation-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(device):\n",
    "    model = SentenceTransformer('xlm-roberta-base')\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def semantic_clustering(corpus, model, k=10, device='cuda'):\n",
    "    corpus_embeddings = model.encode(corpus, device=device)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    clusters = kmeans.fit_predict(corpus_embeddings.cpu().numpy())\n",
    "\n",
    "    cluster_groups = {i: [] for i in range(k)}\n",
    "    for idx, cluster_id in enumerate(clusters):\n",
    "        cluster_groups[cluster_id].append(corpus[idx])\n",
    "    \n",
    "    labels = assign_labels(cluster_groups, device)\n",
    "    \n",
    "    return clusters, labels\n",
    "\n",
    "def assign_labels(cluster_groups, device):\n",
    "    generator = pipeline('text-generation', model='gpt2', device=0 if device == 'cuda' else -1)\n",
    "    labels = []\n",
    "    for cluster_id, items in cluster_groups.items():\n",
    "        prompt = f\"Assign a semantic label to the following claims:\\n\"\n",
    "        for item in items[:5]:  # Limit to first 5 items to avoid exceeding max length\n",
    "            prompt += f\"- {item}\\n\"\n",
    "        prompt += \"Label:\"\n",
    "        \n",
    "        response = generator(prompt, max_length=len(prompt) + 10, num_return_sequences=1)\n",
    "        label = response[0]['generated_text'].split(\"Label:\")[-1].strip()\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def cross_lingual_similarity(query, claim, model, device):\n",
    "    query_embedding = model.encode(query, device=device)\n",
    "    claim_embedding = model.encode(claim, device=device)\n",
    "    return torch.cosine_similarity(query_embedding, claim_embedding, dim=0).item()\n",
    "\n",
    "def evaluate_relevance(query, claim, tokenizer, model, device):\n",
    "    inputs = tokenizer(query, claim, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    relevance_score = torch.softmax(outputs.logits, dim=1)[0][1].item()  # Assuming 1 is the relevant class\n",
    "    return relevance_score\n",
    "\n",
    "def fasttrack_algorithm(queries, corpus, device='cuda'):\n",
    "    if not torch.cuda.is_available() and device == 'cuda':\n",
    "        print(\"CUDA is not available. Using CPU instead.\")\n",
    "        device = 'cpu'\n",
    "    \n",
    "    model = load_model(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"fine-tuned-fact-check-relevance-model\")\n",
    "    relevance_model = AutoModelForSequenceClassification.from_pretrained(\"fine-tuned-fact-check-relevance-model\").to(device)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Stage 1: Semantic Clustering\n",
    "    clusters, labels = semantic_clustering(corpus, model, k=10, device=device)\n",
    "    \n",
    "    # Stage 2: Retrieval and Ranking\n",
    "    for query in queries:\n",
    "        relevant_claims = []\n",
    "        \n",
    "        for cluster in clusters:\n",
    "            for claim in cluster:\n",
    "                similarity = cross_lingual_similarity(query, claim, model, device)\n",
    "                relevance = evaluate_relevance(query, claim, tokenizer, relevance_model, device)\n",
    "                \n",
    "                if similarity > 0.5 and relevance > 0.5:  # Adjust thresholds as needed\n",
    "                    relevant_claims.append((claim, similarity * relevance))\n",
    "        \n",
    "        # Rank the relevant claims\n",
    "        ranked_claims = sorted(relevant_claims, key=lambda x: x[1], reverse=True)\n",
    "        results.append(ranked_claims[:10])  # Top 10 most relevant claims\n",
    "    \n",
    "    return results\n",
    "\n",
    "queries = [\n",
    "    f\"{post['translated_ocr']}\"\n",
    "    for post in posts_subset\n",
    "]\n",
    "\n",
    "corpus = [\n",
    "    f\"{fact['translation_sentence']}\"\n",
    "    for fact in facts_subset\n",
    "]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "fasttrack_algorithm(queries, corpus, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
