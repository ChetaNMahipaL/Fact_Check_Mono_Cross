{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(file_path):\n",
    "    data = []\n",
    "    \n",
    "    # Open the CSV file and use csv.reader to parse it\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            id_ = int(row[0])\n",
    "            original_sentence = row[1].split(',')[0].replace(\"(\", \"\").replace(\"'\", \"\")\n",
    "            translation_sentence = row[1].split(', ')[1].replace(\"'\", \"\") if len(row[1].split(', ')) > 1 else None\n",
    "            language_tag = row[1].split(', ')[-2].replace(\"[('\", \"\").replace(\"'\", \"\")\n",
    "\n",
    "            fact_check_link = row[2].split(', ')[-1].replace(\")]\", \"\").replace(\"[(\", \"\").replace(\"'\",\"\") if len(row[1].split(', ')) > 2 else None\n",
    "            data.append({\n",
    "                \"id\": id_,\n",
    "                \"original_sentence\": original_sentence,\n",
    "                \"translation_sentence\": translation_sentence,\n",
    "                \"language\": language_tag,\n",
    "                \"fact_check_link\": fact_check_link\n",
    "            })\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'fact_checks.csv'\n",
    "data = parse_csv(file_path)\n",
    "\n",
    "# Print the parsed data\n",
    "\n",
    "with open('fact_checks.json', 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(data, jsonfile, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post_id,instances,ocr,verdicts,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(input_string):\n",
    "    # This regular expression keeps only alphabets, numbers, and whitespaces\n",
    "    input_string= re.sub(r'[^\\w\\s\\(\\[\\]\\'\\.)]', '', input_string)\n",
    "    cleaned_string = input_string.lower()\n",
    "    # cleaned_string = re.sub(r'\\s+', ' ', cleaned_string).strip()\n",
    "\n",
    "    return cleaned_string\n",
    "\n",
    "def parse_ocr_response(ocr_response):\n",
    "    # Extract the main OCR text\n",
    "    text_match = re.search(r\"\\[\\(([^[(']]+)\", ocr_response)\n",
    "    text = text_match.group(1) if text_match else \"\"\n",
    "\n",
    "    # Extract the language-probability pairs\n",
    "    lang_prob_match = re.findall(r\"\\('(\\w+)', ([\\d\\.]+)\\)\", ocr_response)\n",
    "    languages_with_probabilities = [(lang, float(prob)) for lang, prob in lang_prob_match]\n",
    "    \n",
    "    return text, languages_with_probabilities\n",
    "\n",
    "\n",
    "def parse_facts_csv(file_path):\n",
    "    data = []\n",
    "    \n",
    "    # Open the CSV file and use csv.reader to parse it\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "       \n",
    "            id_ = int(row[0])\n",
    "            instance = row[1]\n",
    "            ocr = row[2]\n",
    "            verdicts = row[3]\n",
    "            text = row[4]\n",
    "            text = clean_string(text)\n",
    "            ocr = clean_string(ocr)\n",
    "            ocrl,prob = parse_ocr_response(ocr)\n",
    "            \n",
    "            data.append({\n",
    "                \"id\": id_,\n",
    "                \"instance\": instance,\n",
    "                \"ocr\": ocr,\n",
    "                \"ocr1\": ocrl,\n",
    "\n",
    "                \"lang_prob\":prob,\n",
    "                \"verdicts\":verdicts,\n",
    "                \"text\":text\n",
    "            })\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "data_post = parse_facts_csv(\"posts.csv\")\n",
    "\n",
    "with open('posts.json', 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(data_post, jsonfile, indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
