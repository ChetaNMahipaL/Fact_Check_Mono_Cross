{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from googletrans import Translator\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "\n",
    "def libre_translate(text, source_lang='auto', target_lang='en'):\n",
    "    \"\"\"\n",
    "    Translate text using the LibreTranslate API.\n",
    "    \n",
    "    :param text: Text to be translated\n",
    "    :param source_lang: Source language (default is auto-detect)\n",
    "    :param target_lang: Target language (default is English 'en')\n",
    "    :return: Translated text\n",
    "    \"\"\"\n",
    "    url = \"https://libretranslate.de/translate\"\n",
    "    payload = {\n",
    "        \"q\": text,\n",
    "        \"source\": source_lang,\n",
    "        \"target\": target_lang,\n",
    "        \"format\": \"text\"\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return result['translatedText']\n",
    "    else:\n",
    "        return \"Translation error\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(file_path):\n",
    "    data = []\n",
    "    \n",
    "    # Open the CSV file and use csv.reader to parse it\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            id_ = int(row[0])\n",
    "            original_sentence = row[1].split(',')[0].replace(\"(\", \"\").replace(\"'\", \"\")\n",
    "            translation_sentence = row[1].split(', ')[1].replace(\"'\", \"\") if len(row[1].split(', ')) > 1 else None\n",
    "            language_tag = row[1].split(', ')[-2].replace(\"[('\", \"\").replace(\"'\", \"\")\n",
    "\n",
    "            fact_check_link = row[2].split(', ')[-1].replace(\")]\", \"\").replace(\"[(\", \"\").replace(\"'\",\"\") if len(row[1].split(', ')) > 2 else None\n",
    "            data.append({\n",
    "                \"id\": id_,\n",
    "                \"original_sentence\": original_sentence,\n",
    "                \"translation_sentence\": translation_sentence,\n",
    "                \"language\": language_tag,\n",
    "                \"fact_check_link\": fact_check_link\n",
    "            })\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'fact_checks.csv'\n",
    "data = parse_csv(file_path)\n",
    "\n",
    "# Print the parsed data\n",
    "\n",
    "with open('fact_checks.json', 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(data, jsonfile, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post_id,instances,ocr,verdicts,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24431it [00:00, 67820.88it/s]\n"
     ]
    }
   ],
   "source": [
    "def clean_string(input_string):\n",
    "    # This regular expression keeps only alphabets, numbers, and whitespaces\n",
    "    input_string= re.sub(r'[^\\w\\s\\(\\[\\]\\'\\.)]', '', input_string)\n",
    "    cleaned_string = input_string.lower()\n",
    "    # cleaned_string = re.sub(r'\\s+', ' ', cleaned_string).strip()\n",
    "\n",
    "    return cleaned_string\n",
    "\n",
    "def parse_ocr_response(ocr_response):\n",
    "    # Extract the main OCR text\n",
    "    text_match = re.search(r\"\\[\\(([^[(']]+)\", ocr_response)\n",
    "    text = text_match.group(1) if text_match else \"\"\n",
    "\n",
    "    # Extract the language-probability pairs\n",
    "    lang_prob_match = re.findall(r\"\\('(\\w+)', ([\\d\\.]+)\\)\", ocr_response)\n",
    "    languages_with_probabilities = [(lang, float(prob)) for lang, prob in lang_prob_match]\n",
    "    \n",
    "    return text, languages_with_probabilities\n",
    "\n",
    "\n",
    "\n",
    "def translate_text(text, target_language='en'):\n",
    "    # Initialize the Google Translator object\n",
    "    translator = Translator()\n",
    "\n",
    "    # Translate the text to the target language (English)\n",
    "    translation = translator.translate(text, dest=target_language)\n",
    "    \n",
    "    return translation.text\n",
    "\n",
    "def libre_translate(text, source_lang='auto', target_lang='en'):\n",
    "    \"\"\"\n",
    "    Translate text using the LibreTranslate API.\n",
    "    \n",
    "    :param text: Text to be translated\n",
    "    :param source_lang: Source language (default is auto-detect)\n",
    "    :param target_lang: Target language (default is English 'en')\n",
    "    :return: Translated text\n",
    "    \"\"\"\n",
    "    url = \"https://libretranslate.de/translate\"\n",
    "    payload = {\n",
    "        \"q\": text,\n",
    "        \"source\": source_lang,\n",
    "        \"target\": target_lang,\n",
    "        \"format\": \"text\"\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return result['translatedText']\n",
    "    else:\n",
    "        return \"Translation error\"\n",
    "\n",
    "\n",
    "\n",
    "def parse_facts_csv(file_path):\n",
    "    data = []\n",
    "    \n",
    "    # Open the CSV file and use csv.reader to parse it\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        cnt=0\n",
    "        for row in tqdm(reader):\n",
    "            cnt+=1\n",
    "            if(cnt==10):\n",
    "                break\n",
    "       \n",
    "            id_ = int(row[0])\n",
    "            instance = row[1]\n",
    "            ocr = row[2]\n",
    "            verdicts = row[3]\n",
    "            text = row[4]\n",
    "            # text = clean_string(text)\n",
    "            # print(ocr)\n",
    "            # ocrl,prob = parse_ocr_response(ocr)\n",
    "            cnt =1\n",
    "            try:\n",
    "                translated_ocr =ocr.split(\", \\\"\")[1]\n",
    "                if(translated_ocr!=\"\"):\n",
    "                    cnt=0\n",
    "            except:\n",
    "                translated_ocr = None \n",
    "            if cnt!=0:\n",
    "                try:\n",
    "                    a = 2/cnt\n",
    "                    translated_ocr = ocr.split(\", \\'\\\"\")[1]\n",
    "                    if(translated_ocr!=\"\"):\n",
    "                        cnt=0\n",
    "                \n",
    "                except:\n",
    "                    translated_ocr = None\n",
    "            if cnt!=0:\n",
    "                try:\n",
    "                    a = 2/cnt\n",
    "                    translated_ocr = ocr.split(\"\\'\")[3]\n",
    "                    if(translated_ocr!=\"\"):\n",
    "                        cnt=0\n",
    "                    else:\n",
    "                        a = 2/0\n",
    "                \n",
    "                except:\n",
    "                    translated_ocr = ocr.split(\", \\'\\\"\")[0]\n",
    "            ocr = clean_string(ocr)\n",
    "            translated_ocr = clean_string(translated_ocr)\n",
    "        \n",
    "\n",
    "            \n",
    "            data.append({\n",
    "                \"id\": id_,\n",
    "                \"instance\": instance,\n",
    "                \"ocr\": ocr, \n",
    "                \"translated_ocr\":translated_ocr,\n",
    "                \"verdicts\":verdicts,\n",
    "                \"text\":text\n",
    "            })\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "data_post = parse_facts_csv(\"posts.csv\")\n",
    "\n",
    "with open('posts.json', 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(data_post, jsonfile, indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
