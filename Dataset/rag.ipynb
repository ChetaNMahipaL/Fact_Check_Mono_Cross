{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import weaviate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "from langchain.schema import Document\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def remove_emojis_and_punctuation(text):\n",
    "    # Remove emojis\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        print(text[2])\n",
    "        exit(1)\n",
    "        return text\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\" \n",
    "        \"]+\", flags=re.UNICODE\n",
    "    )\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.replace('\\t', ' ').replace('\\n', ' ')\n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted fact check claims saved to ./fact_check_claims.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is just a quick script that is able to load the files. Just using pandas can be tricky because of the newline characters in the text data. Here it is handled via the `parse_col` method.\n",
    "\"\"\"\n",
    "\n",
    "import ast\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "our_dataset_path = '.'\n",
    "\n",
    "posts_path = os.path.join(our_dataset_path, 'posts.csv')\n",
    "fact_checks_path = os.path.join(our_dataset_path, 'fact_checks.csv')\n",
    "\n",
    "parse_col = lambda s: ast.literal_eval(s.replace('\\n', '\\\\n')) if s else s\n",
    "\n",
    "df_fact_checks = pd.read_csv(fact_checks_path).fillna('').set_index('fact_check_id')\n",
    "for col in ['claim', 'title']:\n",
    "    df_fact_checks[col] = df_fact_checks[col].apply(parse_col)\n",
    "\n",
    "\n",
    "df_fact_checks[['claim', 'translated_claim', 'language']] = pd.DataFrame(df_fact_checks['claim'].tolist(), index=df_fact_checks.index)\n",
    "df_fact_checks['claim'] = df_fact_checks['claim'].apply(remove_emojis_and_punctuation)\n",
    "df_fact_checks['translated_claim'] = df_fact_checks['translated_claim'].apply(remove_emojis_and_punctuation)\n",
    "\n",
    "df_fact_check_claims = df_fact_checks[['claim', 'translated_claim', 'language']]\n",
    "\n",
    "\n",
    "# if 'fact_check_id' not in df_fact_check_claims.columns:\n",
    "#     df_fact_check_claims = df_fact_check_claims.reset_index()\n",
    "\n",
    "# Save the extracted data to a new CSV file\n",
    "output_path = os.path.join(our_dataset_path, 'fact_check_claims.csv')\n",
    "df_fact_check_claims.to_csv(output_path, index_label='fact_check_id')\n",
    "\n",
    "print(f\"Extracted fact check claims saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_df = df_fact_checks.head(50)\n",
    "output_path = os.path.join(our_dataset_path, 'sample_fact_check_claims.csv')\n",
    "\n",
    "limited_df.to_csv(output_path, index_label='fact_check_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "ara\n",
      "por\n",
      "por\n",
      "fra\n",
      "eng\n",
      "ara\n",
      "ara\n",
      "ara\n",
      "ara\n",
      "eng\n",
      "msa\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "eng\n",
      "por\n",
      "eng\n",
      "eng\n",
      "por\n",
      "por\n",
      "por\n",
      "por\n",
      "por\n",
      "por\n",
      "por\n",
      "por\n",
      "por\n",
      "por\n",
      "por\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15415/1445028898.py:1: DeprecationWarning: \n",
      "Python client v3 `weaviate.Client(...)` connections and methods are deprecated and will\n",
      "            be removed by 2024-11-30.\n",
      "\n",
      "            Upgrade your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "                - For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "                - For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "\n",
      "            If you have to use v3 code, install the v3 client and pin the v3 dependency in your requirements file: `weaviate-client>=3.26.7;<4.0.0`\n",
      "  client = weaviate.Client(\n",
      "/home/karan/.local/lib/python3.10/site-packages/weaviate/warnings.py:186: DeprecationWarning: Dep016: Python client v3 `weaviate.Client(...)` connections and methods are deprecated and will\n",
      "            be removed by 2024-11-30.\n",
      "\n",
      "            Upgrade your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "                - For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "                - For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "\n",
      "            If you have to use v3 code, install the v3 client and pin the v3 dependency in your requirements file: `weaviate-client>=3.26.7;<4.0.0`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Are avocados good for you\n",
      " Can animals have headaches\n",
      " Can we help prevent Alzheimers with diet\n",
      " Do any benefits of alcohol outweigh the risks\n",
      " Does acupuncture work for headaches\n",
      " Does lack of sleep trigger headaches\n",
      " Does marijuana harm the brain\n",
      " Is Autism prevalence increasing\n",
      " Is it better to drink little alcohol than none at all\n",
      " Is there a psychological component to headaches\n",
      " Should women with fibroids avoid soy\n",
      " can turmeric help control the negative side effects of food allergies\n",
      " بيشرب مياه معدينة مستورده يا ولاد Evianطيب والمياه بتاعت الجيش “صافي” ؟وبعدين بتتقشف ونص مرتبك وفيلم وحوار على الشعب  و سعر المياه الفرنسية “ايفيان” المستورده لمدة شهر لبيتك اكتر من نص مرتبك اللي اكيد مش بتعتمد عليه في حاجه ومجرد شكل\n",
      " As vacinas não passaram pelos protocolos de teste adequados e não são seguras\n",
      " Bill Gates admitiu implantar microchips nas vacinas contra a Covid19\n",
      " Il y a une vidéo qui sera lancée demain à WhatsApp et qui s’appelle Martinelli \n",
      " This Ofcom which looks at us under a magnifying glass and writes us warnings for the previous year wrote more to Fox News than to us\n",
      " تمكنت الشرطة من الوصول إليه وقتل منفذ الاعتداء على مسجد نيوزلاندا \n",
      " محمد رشوان  سبب شهرته يرجع لأولمبيّاد لوس أنجلوس 1984  محمد رشوان وصل للنهائي ضد واحد ياباني  بطل العالم  المصري محمد رشوان تعمّد الخساره قدّامه والسبب ان الياباني في بداية المباراه اتصاب في احد رجليه فرفض محمد رشوان انّه يكسب واحد مصاب دة غير انه السبب فى ان 3000 شخص يابانى اسلم بسبب المباره دى لما سالوه فى مؤتمر صحفى فى اليابان انت ليه رفض تضربه فى رجله المصابه ؟  ابتسم وقال دينى يمنعنى عن ايذائه \n",
      " نيوزلندا  بفضل الله عزوجل المسجد الذي اطلق فيه النار علي المصلين يستقبل اضعاف اضعاف في صلاة المغرب ولهذا نقول للشهداء لا تحزنوا على ما تركتم وافرحوا بما قدمتم ان شاء الله عز وجل الى الفردوس الاعلى من الجنة ونبشركم ان المسجد اصبح يعج بالمصلين بعدكم ومع ذلك الله عز وجل سخر لهم من يحرسهم بصلاتهم\n",
      " هام  لا يفضل تناول أدوية خافضة لدرجة الحرارة ومسكنة لإزالة الآلام والصداع من مجموعة مضادات الألتهاب  NSAID  وأشهرها ‬ ‫البروفين والفولتارين و الإبيوبروفين ‬وغيرها ‫مع المصابين بفيروس الكورونا لانها تقلل المناعة وتزود من تأثير الفيروس على الصدر طبقا لدراسات صغيرة و ومقالات طبية حديثة ‬ ‫ويستخدم بديل لها مجموعة البارسيتامول مثل البانودل والبارامول ‬وغيرها\n",
      " ‘What difference at this point does it make I am the guy that got under her skin and provoked that infamous response from Hillary Clinton by asking a pretty simple question Why didnt you just pick up the phone and call the survivors’ of the Benghazi attack\n",
      "Bangkai KM Sinar Bangun Ditemukan\n",
      "Biden  the Dems are coming to your front door to force you to take the COVID19 vax\n",
      "Broward elections department has a history of violating the law\n",
      "COVID19 did not start in central China’s Wuhan but may come through imported frozen food and packaging experts”\n",
      "FISAMemo shows real collusion between Dem operatives  key officials at the FBI  DOJ to spy on the Trump campaign  interfere in the 2016 election\n",
      "MichaelCohen Convicted of lying to Congress re Russia investigation … ElliottAbrams Convicted of lying to Congress re arming Contra death squads\n",
      "Ukraine’s language law comes into force prohibiting Russian from being spoken by doctors and teachers Clear violation of human rights and MinskAgreements\n",
      "1 billion—that’s how much Bruce Rauner has wasted with his budget crisis\n",
      "21T in Pentagon accounting errors Medicare for All costs 32T That means 66 of Medicare for All could have been funded already by the Pentagon\n",
      "32 trillion — just think of it — in tax cuts for American families\n",
      "4 trillion jobs plan unnecessary because 2020 unemployment was lowest ever without it\n",
      "5000 a year is the burden of Joe Biden’s inflation tax on Wisconsin families\n",
      "53 million a week is coming across the border in drugs\n",
      "575 billion cut from Medicare in Trump’s proposed 2020 budget\n",
      "Bolsonaro lidera maior passeio de moto do planeta Realmente Mito Elon Musk E assim o bilionário Elon Musk dono da Tesla e da Space X se torna o mais novo Bolsominion do planeta\n",
      "Defunding to a lot of people means break up the police forces and either that or dont give them any money so essentially they are breaking it up\n",
      "I Didn’t Want to Go Through the Rioting Juror in Chauvin Trial Makes Stunning Admission over Guilty Verdict\n",
      "PORTUGUESITO Claramente demos confiança a mais a esta gente Uma população branda habituada a bajular figuras de autoridade  a quem basta vestir uma farda ou por uma boa gravata  paga agora o preço da sua própria passividade\n",
      " E menos de 2 de tratamento de esgoto”\n",
      " Ele Rui Costa tem uma avaliação superior a 70 do nosso estado\n",
      " Por favor faça a sua parte para que isto chegue ao fim Se tem família ou amigos que ainda não foram vacinados não os deixe estar em jantares de família não fale com eles ao telefone não lhes responda às mensagens Faça tudo o que puder para lhes dificultar a vida até que eles cumpram\n",
      " Porque os animais estavam morrendo decidiram parar os testes\n",
      " contribuir com a melhoria dos indicadores de saneamento\n",
      " a cidade tem na sua agenda  por exemplo pior saneamento do Brasil\n",
      " apelidaram de marquise um aumento na casa de Cristiano Ronaldo Gostava é que agora esses mesmos que vieram a público quer os mídia quer o povinho que tanto o criticou e satirizou que falassem sobe este nobre gesto Calados Pois é a dor de corno é mesmo lixada\n",
      " e esta organização especial em que a escola vai ter de funcionar como que criando caixas estanques entre cada turma para que cada sala seja só para uma turma cada carteira seja só para um aluno que os lugares sejam sempre os mesmos \n",
      " essa cidade que tem quase 80 de sua população de homens mulheres crianças jovens negros\n",
      " eu moro na China a quase 2 anos… Aqui não teve não tem e não haverá vacina”\n",
      "Vector database has been successfully populated.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "client = weaviate.Client(\n",
    "    embedded_options=EmbeddedOptions()\n",
    ")\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df_fact_checks['claim'].tolist())\n",
    "\n",
    "# Create documents for vector st\n",
    "for i, row in limited_df.iterrows():\n",
    "    embedding = tfidf_matrix[i].toarray().flatten().tolist()  # Convert sparse matrix row to list\n",
    "    new_uuid = str(uuid.uuid4()) \n",
    "    original_index = row.name \n",
    "    print(row['claim'])\n",
    "    \n",
    "    # Create document and insert into Weaviate\n",
    "    client.data_object.create(\n",
    "        data_object={\n",
    "            \"claim\": row['claim'],  # Cleaned claim text\n",
    "            \"translated_claim\": row['translated_claim'],  # Include the translated claim\n",
    "            \"language\": row['language'][0][0],  # Include the language\n",
    "            \"embedding\": embedding,  # BoW embedding\n",
    "            \"original_index\": original_index  # Store the original index for later reference\n",
    "        },\n",
    "        class_name=\"YourClassName\",  # Replace with your desired class name\n",
    "        uuid=new_uuid  # Use the new valid UUID\n",
    "    )\n",
    "\n",
    "print(\"Vector database has been successfully populated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Weaviate as LangchainWeaviate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = LangchainWeaviate(\n",
    "    client=client,\n",
    "    index_name=\"YourClassName\",  # Use the class name you specified in Weaviate\n",
    "    text_key=\"claim\"  # The key that contains the text to be embedded and retrieved\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input sentence\n",
    "input_sentence = \"150 million people\"\n",
    "\n",
    "# Transform the input sentence into a vector\n",
    "input_vector = vectorizer.transform([input_sentence]).toarray().flatten().tolist()\n",
    "\n",
    "\n",
    "nearest_neighbors = (\n",
    "    client.query.get(\"YourClassName\", [\"claim\", \"translated_claim\", \"language\", \"original_index\"])\n",
    "    .with_near_vector({\"vector\": input_vector})\n",
    "    .with_limit(1)  # Get the closest single match\n",
    "    .do()\n",
    ")\n",
    "# Step 3: Extract the closest index and information\n",
    "if nearest_neighbors['data']['Get']['YourClassName']:\n",
    "    closest_match = nearest_neighbors['data']['Get']['YourClassName'][0]\n",
    "    print(f\"Closest match found: {closest_match}\")\n",
    "else:\n",
    "    print(\"No match found, but you can still retrieve the closest claim.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_claims = client.query.get(\"YourClassName\", [\"claim\", \"translated_claim\", \"language\", \"original_index\"]).do()\n",
    "with open(\"./db.txt\" ,\"w\") as f:\n",
    "    for claim_record in all_claims['data']['Get']['YourClassName']:\n",
    "        claim_text = claim_record['claim']\n",
    "        f.write(claim_text+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best matching claim found: {'claim': 'Italy drastically reduced the country’s official COV1D19 death count by over 97 This means Covid killed fewer people than an average seasonal flu”', 'language': \"[('eng', 1.0)]\", 'original_index': 2957, 'translated_claim': 'Italy drastically reduced the country’s official COV1D19 death count by over 97 This means Covid killed fewer people than an average seasonal flu”'}\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"COV1D19 death\"\n",
    "\n",
    "def calculate_word_similarity(input_sentence, claim):\n",
    "    input_words = set(input_sentence.lower().split())\n",
    "    claim_words = set(claim.lower().split())\n",
    "    # Count the number of shared words\n",
    "    return len(input_words.intersection(claim_words))\n",
    "\n",
    "# Fetch all claims from Weaviate\n",
    "all_claims = client.query.get(\"YourClassName\", [\"claim\", \"translated_claim\", \"language\", \"original_index\"]).do()\n",
    "\n",
    "# Initialize variables to track the best match\n",
    "best_score = 0\n",
    "best_claim = None\n",
    "\n",
    "# Loop through all claims to find the most similar one\n",
    "for claim_record in all_claims['data']['Get']['YourClassName']:\n",
    "    claim_text = claim_record['claim']\n",
    "    # print(claim_text)\n",
    "    score = calculate_word_similarity(input_sentence, claim_text)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_claim = claim_record\n",
    "\n",
    "# Output the best matching claim\n",
    "if best_claim:\n",
    "    print(f\"Best matching claim found: {best_claim}\")\n",
    "else:\n",
    "    print(\"No matching claim found.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Initialize OpenAI API\n",
    "openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "def predict_fact_match(sentence, fact_check, model_name=\"fine-tuned-gpt-model\"):\n",
    "    prompt = f\"Input: {sentence}\\nFact Check: {fact_check}\\nOutput (1 or 0):\"\n",
    "    response = openai.Completion.create(\n",
    "        model=model_name,\n",
    "        prompt=prompt,\n",
    "        max_tokens=1,\n",
    "        temperature=0  # Reduce randomness for classification tasks\n",
    "    )\n",
    "    return int(response['choices'][0]['text'].strip())  # Expecting 1 or 0\n",
    "\n",
    "# Example call\n",
    "sentence = \"150 million people\"\n",
    "fact_check = \"A recent census estimated the population to be close to 150 million.\"\n",
    "print(predict_fact_match(sentence, fact_check, model_name=\"fine-tuned-gpt-model\"))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
